{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from __future__ import print_function\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(words):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    wordsFiltered = \"\"\n",
    "    words=words.split()\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered+=w+\" \"\n",
    "    return wordsFiltered\n",
    "\n",
    "\n",
    "data = ET.parse('ABSA15_Restaurants_Test.xml')\n",
    "reviews = data.getroot()\n",
    "dataset=[]\n",
    "pos_tags=[]\n",
    "all_data=[]\n",
    "sentences1=[]\n",
    "z=open('all_text.txt','w')\n",
    "for review in reviews:\n",
    "        sentences = review[0]\n",
    "        for sentence in sentences:\n",
    "            raw_text = sentence[0].text.strip()\n",
    "            tokens_temp = word_tokenize(raw_text)\n",
    "            tags=nltk.pos_tag(tokens_temp)\n",
    "            pos_tags.append(nltk.pos_tag(tokens_temp))\n",
    "            words = word_tokenize(sentence[0].text.strip())\n",
    "            aspects=[]\n",
    "            sample = [words, []]\n",
    "            if len(sentence)>1:\n",
    "                opinions=sentence[1]\n",
    "                for opinion in opinions:\n",
    "                    firstLetter = int(opinion.attrib['from'])\n",
    "                    lastLetter = int(opinion.attrib['to'])\n",
    "                    if firstLetter!=lastLetter:\n",
    "                        lastLetter = int(opinion.attrib['to'])\n",
    "                        if firstLetter!=lastLetter:\n",
    "                            aspects.append(raw_text[firstLetter:lastLetter])\n",
    "                if len(aspects)==0:\n",
    "                    continue\n",
    "                tagged=[]\n",
    "                tokens_temp = word_tokenize(filter_words(raw_text))\n",
    "                tags=nltk.pos_tag(tokens_temp)\n",
    "                \n",
    "                \n",
    "                for t in tags:\n",
    "                    for aspect in aspects:\n",
    "                        if t[0] in aspects:\n",
    "                            tagged.append((t[0], t[1], 1))\n",
    "                        else:\n",
    "                            tagged.append((t[0], t[1], 0))\n",
    "                sentences1.append(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_sentences2.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences1, f)\n",
    "with open('train_sentences2.pkl', 'rb') as f:\n",
    "    train_sentences = pickle.load(f)\n",
    "# print(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT', 0), ('Cypriot', 'NNP', 0), ('restaurant', 'NN', 0), ('lot', 'NN', 0), ('going', 'VBG', 0), ('it', 'PRP', 0), ('.', '.', 0)]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "for s in train_sentences:\n",
    "    #print(s)\n",
    "    c = 0\n",
    "    for w in s:\n",
    "        #print(w)\n",
    "        if w[2]: c += 1\n",
    "    if c > maxx: maxx = c\n",
    "\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "\n",
    "for s in train_sentences:\n",
    "    for t in s:\n",
    "        word_set.add(t[0])\n",
    "# print(word_set)\n",
    "\n",
    "words = list(word_set)\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "n_words = len(words); n_words\n",
    "max_len = 35\n",
    "word2idx = {w: i+1 for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
    "# print (X)\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [[w[2] for w in s] for s in train_sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandaru\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=35)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324 samples, validate on 37 samples\n",
      "Epoch 1/50\n",
      "324/324 [==============================] - 2s 6ms/step - loss: 0.6513 - acc: 0.8673 - f1: 0.0581 - precision: 0.0477 - recall: 0.1424 - val_loss: 0.5513 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "324/324 [==============================] - 0s 938us/step - loss: 0.3499 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1865 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "324/324 [==============================] - 0s 977us/step - loss: 0.1729 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1741 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1455 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1738 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1404 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1691 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1331 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1705 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1306 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1672 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1280 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1678 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1249 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1692 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1227 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1675 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1700 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1175 - acc: 0.9583 - f1: 0.0083 - precision: 0.1481 - recall: 0.0043 - val_loss: 0.1705 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1156 - acc: 0.9578 - f1: 0.0261 - precision: 0.3128 - recall: 0.0137 - val_loss: 0.1723 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1117 - acc: 0.9582 - f1: 0.0301 - precision: 0.2239 - recall: 0.0163 - val_loss: 0.1708 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1097 - acc: 0.9583 - f1: 0.0432 - precision: 0.4066 - recall: 0.0230 - val_loss: 0.1756 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9586 - f1: 0.0975 - precision: 0.4771 - recall: 0.0565 - val_loss: 0.1761 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1052 - acc: 0.9589 - f1: 0.0989 - precision: 0.3994 - recall: 0.0594 - val_loss: 0.1778 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1026 - acc: 0.9595 - f1: 0.1594 - precision: 0.5894 - recall: 0.0957 - val_loss: 0.1799 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0993 - acc: 0.9604 - f1: 0.1463 - precision: 0.6050 - recall: 0.0853 - val_loss: 0.1855 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0964 - acc: 0.9613 - f1: 0.1963 - precision: 0.5911 - recall: 0.1248 - val_loss: 0.1818 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0929 - acc: 0.9614 - f1: 0.2153 - precision: 0.6563 - recall: 0.1420 - val_loss: 0.1930 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0913 - acc: 0.9615 - f1: 0.2496 - precision: 0.7152 - recall: 0.1618 - val_loss: 0.1848 - val_acc: 0.9498 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0872 - acc: 0.9638 - f1: 0.3408 - precision: 0.6619 - recall: 0.2354 - val_loss: 0.1942 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0841 - acc: 0.9635 - f1: 0.2853 - precision: 0.6617 - recall: 0.1862 - val_loss: 0.1971 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9677 - f1: 0.4689 - precision: 0.7378 - recall: 0.3495 - val_loss: 0.2059 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0781 - acc: 0.9665 - f1: 0.3865 - precision: 0.7808 - recall: 0.2684 - val_loss: 0.2026 - val_acc: 0.9514 - val_f1: 0.0293 - val_precision: 0.8649 - val_recall: 0.0149\n",
      "Epoch 27/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0749 - acc: 0.9698 - f1: 0.5066 - precision: 0.7449 - recall: 0.3920 - val_loss: 0.2037 - val_acc: 0.9514 - val_f1: 0.0293 - val_precision: 0.8649 - val_recall: 0.0149\n",
      "Epoch 28/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0724 - acc: 0.9715 - f1: 0.5462 - precision: 0.7925 - recall: 0.4202 - val_loss: 0.2071 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0686 - acc: 0.9735 - f1: 0.6098 - precision: 0.7865 - recall: 0.5074 - val_loss: 0.2211 - val_acc: 0.9490 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0652 - acc: 0.9706 - f1: 0.5240 - precision: 0.7841 - recall: 0.4003 - val_loss: 0.2334 - val_acc: 0.9490 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0620 - acc: 0.9746 - f1: 0.6044 - precision: 0.8070 - recall: 0.4986 - val_loss: 0.2178 - val_acc: 0.9490 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0591 - acc: 0.9760 - f1: 0.6447 - precision: 0.8274 - recall: 0.5382 - val_loss: 0.2324 - val_acc: 0.9475 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0567 - acc: 0.9766 - f1: 0.6463 - precision: 0.8438 - recall: 0.5345 - val_loss: 0.2255 - val_acc: 0.9490 - val_f1: 0.0279 - val_precision: 0.2162 - val_recall: 0.0149\n",
      "Epoch 34/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0532 - acc: 0.9779 - f1: 0.6643 - precision: 0.8213 - recall: 0.5711 - val_loss: 0.2478 - val_acc: 0.9444 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0506 - acc: 0.9805 - f1: 0.7365 - precision: 0.8442 - recall: 0.6562 - val_loss: 0.2454 - val_acc: 0.9459 - val_f1: 0.0266 - val_precision: 0.1236 - val_recall: 0.0149\n",
      "Epoch 36/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0480 - acc: 0.9816 - f1: 0.7296 - precision: 0.8554 - recall: 0.6403 - val_loss: 0.2718 - val_acc: 0.9475 - val_f1: 0.0652 - val_precision: 0.2587 - val_recall: 0.0374\n",
      "Epoch 37/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0446 - acc: 0.9832 - f1: 0.7723 - precision: 0.8762 - recall: 0.7025 - val_loss: 0.2639 - val_acc: 0.9444 - val_f1: 0.0592 - val_precision: 0.1541 - val_recall: 0.0374\n",
      "Epoch 38/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0424 - acc: 0.9840 - f1: 0.7800 - precision: 0.9168 - recall: 0.6835 - val_loss: 0.2700 - val_acc: 0.9421 - val_f1: 0.0247 - val_precision: 0.0721 - val_recall: 0.0149\n",
      "Epoch 39/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0415 - acc: 0.9848 - f1: 0.8045 - precision: 0.8602 - recall: 0.7630 - val_loss: 0.2590 - val_acc: 0.9475 - val_f1: 0.1138 - val_precision: 0.3710 - val_recall: 0.0673\n",
      "Epoch 40/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0369 - acc: 0.9858 - f1: 0.8075 - precision: 0.8901 - recall: 0.7416 - val_loss: 0.2681 - val_acc: 0.9436 - val_f1: 0.0825 - val_precision: 0.2006 - val_recall: 0.0523\n",
      "Epoch 41/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0357 - acc: 0.9870 - f1: 0.8296 - precision: 0.8795 - recall: 0.7871 - val_loss: 0.2789 - val_acc: 0.9444 - val_f1: 0.0832 - val_precision: 0.2117 - val_recall: 0.0523\n",
      "Epoch 42/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0336 - acc: 0.9881 - f1: 0.8393 - precision: 0.9051 - recall: 0.7888 - val_loss: 0.2846 - val_acc: 0.9459 - val_f1: 0.1117 - val_precision: 0.3347 - val_recall: 0.0673\n",
      "Epoch 43/50\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.0305 - acc: 0.9899 - f1: 0.8687 - precision: 0.9080 - recall: 0.8362 - val_loss: 0.2883 - val_acc: 0.9429 - val_f1: 0.0480 - val_precision: 0.1236 - val_recall: 0.0298\n",
      "Epoch 44/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0285 - acc: 0.9909 - f1: 0.8774 - precision: 0.9220 - recall: 0.8384 - val_loss: 0.2887 - val_acc: 0.9444 - val_f1: 0.1138 - val_precision: 0.2402 - val_recall: 0.0746\n",
      "Epoch 45/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0284 - acc: 0.9916 - f1: 0.8926 - precision: 0.9098 - recall: 0.8804 - val_loss: 0.3181 - val_acc: 0.9429 - val_f1: 0.0480 - val_precision: 0.1236 - val_recall: 0.0298\n",
      "Epoch 46/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0265 - acc: 0.9915 - f1: 0.8924 - precision: 0.9277 - recall: 0.8641 - val_loss: 0.2899 - val_acc: 0.9429 - val_f1: 0.1109 - val_precision: 0.2162 - val_recall: 0.0746\n",
      "Epoch 47/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0249 - acc: 0.9932 - f1: 0.9151 - precision: 0.9411 - recall: 0.8922 - val_loss: 0.3120 - val_acc: 0.9405 - val_f1: 0.0674 - val_precision: 0.1366 - val_recall: 0.0447\n",
      "Epoch 48/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0233 - acc: 0.9932 - f1: 0.9136 - precision: 0.9626 - recall: 0.8709 - val_loss: 0.3097 - val_acc: 0.9436 - val_f1: 0.0923 - val_precision: 0.2035 - val_recall: 0.0596\n",
      "Epoch 49/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0214 - acc: 0.9937 - f1: 0.9162 - precision: 0.9450 - recall: 0.8915 - val_loss: 0.3235 - val_acc: 0.9452 - val_f1: 0.1524 - val_precision: 0.3754 - val_recall: 0.0971\n",
      "Epoch 50/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0207 - acc: 0.9943 - f1: 0.9272 - precision: 0.9567 - recall: 0.9006 - val_loss: 0.3225 - val_acc: 0.9413 - val_f1: 0.0899 - val_precision: 0.1821 - val_recall: 0.0596\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dbc858530994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# plt.plot(hist[\"acc\"] , label='acc')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras_contrib.layers import CRF\n",
    "\n",
    "earlyStopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=max_len, input_length=max_len))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Bidirectional(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1)))\n",
    "# model.add(Bidirectional(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1))\n",
    "# model.add(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(activation='sigmoid', output_dim=max_len))\n",
    "\n",
    "\n",
    "# # model = Model(inputt, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", f1, precision, recall])\n",
    "\n",
    "history = model.fit(X_tr, y_tr, batch_size=32, epochs=50, validation_split=0.1, verbose=1, callbacks=[])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(12,12))\n",
    "# plt.plot(hist[\"acc\"] , label='acc')\n",
    "# plt.plot(hist[\"val_acc\"] , label='val_acc')\n",
    "\n",
    "# plt.plot(hist['loss'], label='loss')\n",
    "# plt.plot(hist['val_loss'], label='val_loss')\n",
    "plt.plot(hist['precision'], label='precision')\n",
    "plt.plot(hist['val_precision'], label='val_precision')\n",
    "plt.plot(hist['recall'], label='recall')\n",
    "plt.plot(hist['val_recall'], label='val_recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.43137254902\n",
      "Recall : 0.323529411765\n",
      "F1-score : 0.36974789916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "pred_y_te = model.predict(X_te)\n",
    "# pred_y_te = np.round(pred_y_te)\n",
    "pred_y_te = np.array([ [0 if e < threshold else 1 for e in p] for p in pred_y_te ])\n",
    "\n",
    "pred_y_te[6]\n",
    "\n",
    "print('Precision : ' + str(precision_score(y_te, pred_y_te, average='micro')))\n",
    "print('Recall : ' + str(recall_score(y_te, pred_y_te, average='micro')))\n",
    "print('F1-score : ' + str(f1_score(y_te, pred_y_te, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
