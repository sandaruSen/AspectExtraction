{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_sentences.pkl', 'rb') as f:\n",
    "    train_sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "maxx = 0\n",
    "for s in train_sentences:\n",
    "    #print(s)\n",
    "    c = 0\n",
    "    for w in s:\n",
    "        #print(w)\n",
    "        if w[2]: c += 1\n",
    "    if c > maxx: maxx = c\n",
    "\n",
    "print(maxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "\n",
    "for s in train_sentences:\n",
    "    for t in s:\n",
    "        word_set.add(t[0])\n",
    "# print(word_set)\n",
    "\n",
    "words = list(word_set)\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "n_words = len(words); n_words\n",
    "max_len = 35\n",
    "word2idx = {w: i+1 for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
    "# print (X)\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [[w[2] for w in s] for s in train_sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*((prec*rec)/(prec+rec+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandaru\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=35)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324 samples, validate on 37 samples\n",
      "Epoch 1/50\n",
      "324/324 [==============================] - 2s 7ms/step - loss: 0.6417 - acc: 0.8618 - f1: 0.0433 - precision: 0.0359 - recall: 0.1258 - val_loss: 0.5225 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.3176 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1873 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1881 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1759 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1453 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1756 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.1400 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1705 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1351 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1700 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1685 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1294 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1677 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1263 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1682 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1237 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1679 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1212 - acc: 0.9584 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1693 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1182 - acc: 0.9582 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1701 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1167 - acc: 0.9580 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1731 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9578 - f1: 0.0031 - precision: 0.0988 - recall: 0.0016 - val_loss: 0.1739 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1116 - acc: 0.9578 - f1: 0.0282 - precision: 0.2601 - recall: 0.0152 - val_loss: 0.1794 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9582 - f1: 0.0497 - precision: 0.4675 - recall: 0.0270 - val_loss: 0.1745 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1074 - acc: 0.9580 - f1: 0.0797 - precision: 0.3709 - recall: 0.0452 - val_loss: 0.1811 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1040 - acc: 0.9589 - f1: 0.0580 - precision: 0.4565 - recall: 0.0316 - val_loss: 0.1858 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.1027 - acc: 0.9597 - f1: 0.1983 - precision: 0.6430 - recall: 0.1284 - val_loss: 0.1892 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "324/324 [==============================] - 0s 2ms/step - loss: 0.0985 - acc: 0.9609 - f1: 0.1611 - precision: 0.5703 - recall: 0.0953 - val_loss: 0.1918 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0943 - acc: 0.9618 - f1: 0.2035 - precision: 0.6864 - recall: 0.1250 - val_loss: 0.1935 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0912 - acc: 0.9635 - f1: 0.2423 - precision: 0.7190 - recall: 0.1487 - val_loss: 0.2023 - val_acc: 0.9506 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0889 - acc: 0.9643 - f1: 0.3487 - precision: 0.7386 - recall: 0.2430 - val_loss: 0.2015 - val_acc: 0.9498 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0855 - acc: 0.9662 - f1: 0.3915 - precision: 0.8055 - recall: 0.2711 - val_loss: 0.2149 - val_acc: 0.9498 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0830 - acc: 0.9660 - f1: 0.3671 - precision: 0.7098 - recall: 0.2580 - val_loss: 0.2124 - val_acc: 0.9490 - val_f1: 0.0270 - val_precision: 0.0338 - val_recall: 0.0225\n",
      "Epoch 26/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0792 - acc: 0.9685 - f1: 0.4759 - precision: 0.7615 - recall: 0.3557 - val_loss: 0.2210 - val_acc: 0.9490 - val_f1: 0.0270 - val_precision: 0.0338 - val_recall: 0.0225\n",
      "Epoch 27/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0765 - acc: 0.9681 - f1: 0.4747 - precision: 0.7133 - recall: 0.3596 - val_loss: 0.2215 - val_acc: 0.9452 - val_f1: 0.0516 - val_precision: 0.1712 - val_recall: 0.0374\n",
      "Epoch 28/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0727 - acc: 0.9700 - f1: 0.5097 - precision: 0.7650 - recall: 0.3978 - val_loss: 0.2296 - val_acc: 0.9459 - val_f1: 0.0246 - val_precision: 0.0270 - val_recall: 0.0225\n",
      "Epoch 29/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0700 - acc: 0.9705 - f1: 0.5430 - precision: 0.7370 - recall: 0.4492 - val_loss: 0.2341 - val_acc: 0.9459 - val_f1: 0.0246 - val_precision: 0.0270 - val_recall: 0.0225\n",
      "Epoch 30/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0671 - acc: 0.9728 - f1: 0.5742 - precision: 0.8156 - recall: 0.4542 - val_loss: 0.2364 - val_acc: 0.9459 - val_f1: 0.0520 - val_precision: 0.2000 - val_recall: 0.0374\n",
      "Epoch 31/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0633 - acc: 0.9758 - f1: 0.6423 - precision: 0.8028 - recall: 0.5474 - val_loss: 0.2405 - val_acc: 0.9452 - val_f1: 0.0516 - val_precision: 0.1712 - val_recall: 0.0374\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0611 - acc: 0.9764 - f1: 0.6372 - precision: 0.8373 - recall: 0.5262 - val_loss: 0.2446 - val_acc: 0.9421 - val_f1: 0.0246 - val_precision: 0.0270 - val_recall: 0.0225\n",
      "Epoch 33/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0591 - acc: 0.9757 - f1: 0.6546 - precision: 0.8045 - recall: 0.5616 - val_loss: 0.2393 - val_acc: 0.9459 - val_f1: 0.0520 - val_precision: 0.2000 - val_recall: 0.0374\n",
      "Epoch 34/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0551 - acc: 0.9789 - f1: 0.7040 - precision: 0.8551 - recall: 0.6069 - val_loss: 0.2428 - val_acc: 0.9452 - val_f1: 0.0516 - val_precision: 0.1712 - val_recall: 0.0374\n",
      "Epoch 35/50\n",
      "324/324 [==============================] - 1s 2ms/step - loss: 0.0534 - acc: 0.9804 - f1: 0.7459 - precision: 0.8105 - recall: 0.6958 - val_loss: 0.2464 - val_acc: 0.9444 - val_f1: 0.0512 - val_precision: 0.1506 - val_recall: 0.0374\n",
      "Epoch 36/50\n",
      "324/324 [==============================] - 1s 2ms/step - loss: 0.0501 - acc: 0.9798 - f1: 0.7005 - precision: 0.9014 - recall: 0.5840 - val_loss: 0.2398 - val_acc: 0.9436 - val_f1: 0.0508 - val_precision: 0.1351 - val_recall: 0.0374\n",
      "Epoch 37/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0457 - acc: 0.9840 - f1: 0.7806 - precision: 0.8730 - recall: 0.7139 - val_loss: 0.2589 - val_acc: 0.9436 - val_f1: 0.0508 - val_precision: 0.1351 - val_recall: 0.0374\n",
      "Epoch 38/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0426 - acc: 0.9840 - f1: 0.7739 - precision: 0.8967 - recall: 0.6858 - val_loss: 0.2536 - val_acc: 0.9429 - val_f1: 0.0747 - val_precision: 0.1843 - val_recall: 0.0523\n",
      "Epoch 39/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0395 - acc: 0.9856 - f1: 0.8196 - precision: 0.8870 - recall: 0.7660 - val_loss: 0.2610 - val_acc: 0.9444 - val_f1: 0.0532 - val_precision: 0.1419 - val_recall: 0.0374\n",
      "Epoch 40/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0377 - acc: 0.9859 - f1: 0.8078 - precision: 0.9059 - recall: 0.7333 - val_loss: 0.2686 - val_acc: 0.9413 - val_f1: 0.0496 - val_precision: 0.1057 - val_recall: 0.0374\n",
      "Epoch 41/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0366 - acc: 0.9875 - f1: 0.8393 - precision: 0.9010 - recall: 0.7877 - val_loss: 0.2739 - val_acc: 0.9429 - val_f1: 0.0525 - val_precision: 0.1203 - val_recall: 0.0374\n",
      "Epoch 42/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0334 - acc: 0.9880 - f1: 0.8423 - precision: 0.9143 - recall: 0.7857 - val_loss: 0.2787 - val_acc: 0.9459 - val_f1: 0.0541 - val_precision: 0.1779 - val_recall: 0.0374\n",
      "Epoch 43/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0314 - acc: 0.9892 - f1: 0.8536 - precision: 0.9215 - recall: 0.7990 - val_loss: 0.2812 - val_acc: 0.9421 - val_f1: 0.0758 - val_precision: 0.1668 - val_recall: 0.0523\n",
      "Epoch 44/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0295 - acc: 0.9896 - f1: 0.8718 - precision: 0.9090 - recall: 0.8387 - val_loss: 0.2905 - val_acc: 0.9436 - val_f1: 0.0772 - val_precision: 0.1910 - val_recall: 0.0523\n",
      "Epoch 45/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0292 - acc: 0.9899 - f1: 0.8669 - precision: 0.9184 - recall: 0.8242 - val_loss: 0.3002 - val_acc: 0.9436 - val_f1: 0.0754 - val_precision: 0.2000 - val_recall: 0.0523\n",
      "Epoch 46/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0271 - acc: 0.9903 - f1: 0.8780 - precision: 0.9233 - recall: 0.8409 - val_loss: 0.2942 - val_acc: 0.9436 - val_f1: 0.1207 - val_precision: 0.2741 - val_recall: 0.0822\n",
      "Epoch 47/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0243 - acc: 0.9922 - f1: 0.8996 - precision: 0.9532 - recall: 0.8560 - val_loss: 0.3062 - val_acc: 0.9436 - val_f1: 0.1207 - val_precision: 0.2741 - val_recall: 0.0822\n",
      "Epoch 48/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0236 - acc: 0.9934 - f1: 0.9152 - precision: 0.9515 - recall: 0.8836 - val_loss: 0.3128 - val_acc: 0.9429 - val_f1: 0.0977 - val_precision: 0.2266 - val_recall: 0.0673\n",
      "Epoch 49/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0213 - acc: 0.9939 - f1: 0.9230 - precision: 0.9474 - recall: 0.9009 - val_loss: 0.3279 - val_acc: 0.9444 - val_f1: 0.0762 - val_precision: 0.2192 - val_recall: 0.0523\n",
      "Epoch 50/50\n",
      "324/324 [==============================] - 0s 1ms/step - loss: 0.0200 - acc: 0.9945 - f1: 0.9310 - precision: 0.9615 - recall: 0.9039 - val_loss: 0.3204 - val_acc: 0.9398 - val_f1: 0.1144 - val_precision: 0.2091 - val_recall: 0.0822\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-dbc858530994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# plt.plot(hist[\"acc\"] , label='acc')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras_contrib.layers import CRF\n",
    "\n",
    "earlyStopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=max_len, input_length=max_len))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Bidirectional(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1)))\n",
    "# model.add(Bidirectional(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1))\n",
    "# model.add(LSTM(units=max_len, return_sequences=True, recurrent_dropout=0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(activation='sigmoid', output_dim=max_len))\n",
    "\n",
    "\n",
    "# # model = Model(inputt, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", f1, precision, recall])\n",
    "\n",
    "history = model.fit(X_tr, y_tr, batch_size=32, epochs=50, validation_split=0.1, verbose=1, callbacks=[])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(12,12))\n",
    "# plt.plot(hist[\"acc\"] , label='acc')\n",
    "# plt.plot(hist[\"val_acc\"] , label='val_acc')\n",
    "\n",
    "# plt.plot(hist['loss'], label='loss')\n",
    "# plt.plot(hist['val_loss'], label='val_loss')\n",
    "plt.plot(hist['precision'], label='precision')\n",
    "plt.plot(hist['val_precision'], label='val_precision')\n",
    "plt.plot(hist['recall'], label='recall')\n",
    "plt.plot(hist['val_recall'], label='val_recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.47619047619\n",
      "Recall : 0.294117647059\n",
      "F1-score : 0.363636363636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "pred_y_te = model.predict(X_te)\n",
    "# pred_y_te = np.round(pred_y_te)\n",
    "pred_y_te = np.array([ [0 if e < threshold else 1 for e in p] for p in pred_y_te ])\n",
    "\n",
    "pred_y_te[6]\n",
    "\n",
    "print('Precision : ' + str(precision_score(y_te, pred_y_te, average='micro')))\n",
    "print('Recall : ' + str(recall_score(y_te, pred_y_te, average='micro')))\n",
    "print('F1-score : ' + str(f1_score(y_te, pred_y_te, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
